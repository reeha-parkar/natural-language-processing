{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary dependencies\n",
    "import nltk, re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagging using CRF\n"
     ]
    }
   ],
   "source": [
    "print('POS Tagging using CRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tagged sentences =  3914\n"
     ]
    }
   ],
   "source": [
    "# Use tagset\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
    "print('Number of tagged sentences = ', len(tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tagged words =  100676\n"
     ]
    }
   ],
   "source": [
    "tagged_words = [tup for sent in tagged_sentences for tup in sent]\n",
    "print('Total number of tagged words = ', len(tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of the corpus =  12408\n"
     ]
    }
   ],
   "source": [
    "vocab = set([word for word, tag in tagged_words])\n",
    "print('Vocabulary of the corpus = ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique tags in the corpus:  {'NOUN', 'ADP', 'DET', 'PRT', 'VERB', 'X', 'PRON', '.', 'CONJ', 'ADJ', 'ADV', 'NUM'}\n",
      "Number of tags in the corpus =  12\n"
     ]
    }
   ],
   "source": [
    "tags = set([tag for word, tag in tagged_words])\n",
    "print('The unique tags in the corpus: ', tags)\n",
    "print('Number of tags in the corpus = ', len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in training data =  3131\n",
      "Number of sentences in testing data =  783\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into train and test set -> 80-20 split\n",
    "train_set, test_set = train_test_split(tagged_sentences, test_size=0.2, random_state=1234)\n",
    "print('Number of sentences in training data = ', len(train_set))\n",
    "print('Number of sentences in testing data = ', len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature function\n",
    "def features(sentence, index):\n",
    "    # sentence: [w1, w2, w3, ...], index is the position of the word in the sentence\n",
    "    return {\n",
    "        'is_first_capital': int(sentence[index][0].isupper()),\n",
    "        'is_first_word': int(index==0),\n",
    "        'is_last_word': int(index==len(sentence)-1),\n",
    "        'is_complete_capital': int(sentence[index].upper()==sentence[index]),\n",
    "        'prev_word': '' if index==0 else sentence[index-1],\n",
    "        'next_word': '' if index==len(sentence)-1 else sentence[index+1],\n",
    "        'is_numeric': int(sentence[index].isdigit()),\n",
    "        'is_alphanumeric': int(bool((re.match('^(?=.*[a-zA-Z])',sentence[index])))),\n",
    "        'prefix_1': sentence[index][0],\n",
    "        'prefix_2': sentence[index][:2],\n",
    "        'prefix_3': sentence[index][:3],\n",
    "        'prefix_4': sentence[index][:4],\n",
    "        'suffix_1': sentence[index][-1],\n",
    "        'suffix_2': sentence[index][-2:],\n",
    "        'suffix_3': sentence[index][-3:],\n",
    "        'suffix_4': sentence[index][-4:],\n",
    "        'word_has_hyphen': 1 if '-' in sentence[index] else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels and the sentences in both training and testing data\n",
    "def untag(sentence):\n",
    "    return [word for word, tag in sentence]\n",
    "\n",
    "def prepare_data(tagged_sentss):\n",
    "    X, y = [], []\n",
    "    for sent in tagged_sentss:\n",
    "        X.append([features(untag(sent), index) for index in range(len(sent))])\n",
    "        y.append([tag for word, tag in sent])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training data:  [{'is_first_capital': 1, 'is_first_word': 1, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': '', 'next_word': 'Wall', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'O', 'prefix_2': 'On', 'prefix_3': 'On', 'prefix_4': 'On', 'suffix_1': 'n', 'suffix_2': 'On', 'suffix_3': 'On', 'suffix_4': 'On', 'word_has_hyphen': 0}, {'is_first_capital': 1, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'On', 'next_word': 'Street', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'W', 'prefix_2': 'Wa', 'prefix_3': 'Wal', 'prefix_4': 'Wall', 'suffix_1': 'l', 'suffix_2': 'll', 'suffix_3': 'all', 'suffix_4': 'Wall', 'word_has_hyphen': 0}, {'is_first_capital': 1, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'Wall', 'next_word': 'men', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'S', 'prefix_2': 'St', 'prefix_3': 'Str', 'prefix_4': 'Stre', 'suffix_1': 't', 'suffix_2': 'et', 'suffix_3': 'eet', 'suffix_4': 'reet', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'Street', 'next_word': 'and', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'm', 'prefix_2': 'me', 'prefix_3': 'men', 'prefix_4': 'men', 'suffix_1': 'n', 'suffix_2': 'en', 'suffix_3': 'men', 'suffix_4': 'men', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'men', 'next_word': 'women', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'a', 'prefix_2': 'an', 'prefix_3': 'and', 'prefix_4': 'and', 'suffix_1': 'd', 'suffix_2': 'nd', 'suffix_3': 'and', 'suffix_4': 'and', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'and', 'next_word': 'walk', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'w', 'prefix_2': 'wo', 'prefix_3': 'wom', 'prefix_4': 'wome', 'suffix_1': 'n', 'suffix_2': 'en', 'suffix_3': 'men', 'suffix_4': 'omen', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'women', 'next_word': 'with', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'w', 'prefix_2': 'wa', 'prefix_3': 'wal', 'prefix_4': 'walk', 'suffix_1': 'k', 'suffix_2': 'lk', 'suffix_3': 'alk', 'suffix_4': 'walk', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'walk', 'next_word': 'great', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'w', 'prefix_2': 'wi', 'prefix_3': 'wit', 'prefix_4': 'with', 'suffix_1': 'h', 'suffix_2': 'th', 'suffix_3': 'ith', 'suffix_4': 'with', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'with', 'next_word': 'purpose', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'g', 'prefix_2': 'gr', 'prefix_3': 'gre', 'prefix_4': 'grea', 'suffix_1': 't', 'suffix_2': 'at', 'suffix_3': 'eat', 'suffix_4': 'reat', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'great', 'next_word': ',', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'p', 'prefix_2': 'pu', 'prefix_3': 'pur', 'prefix_4': 'purp', 'suffix_1': 'e', 'suffix_2': 'se', 'suffix_3': 'ose', 'suffix_4': 'pose', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 1, 'prev_word': 'purpose', 'next_word': '*-2', 'is_numeric': 0, 'is_alphanumeric': 0, 'prefix_1': ',', 'prefix_2': ',', 'prefix_3': ',', 'prefix_4': ',', 'suffix_1': ',', 'suffix_2': ',', 'suffix_3': ',', 'suffix_4': ',', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 1, 'prev_word': ',', 'next_word': 'noticing', 'is_numeric': 0, 'is_alphanumeric': 0, 'prefix_1': '*', 'prefix_2': '*-', 'prefix_3': '*-2', 'prefix_4': '*-2', 'suffix_1': '2', 'suffix_2': '-2', 'suffix_3': '*-2', 'suffix_4': '*-2', 'word_has_hyphen': 1}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': '*-2', 'next_word': 'one', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'n', 'prefix_2': 'no', 'prefix_3': 'not', 'prefix_4': 'noti', 'suffix_1': 'g', 'suffix_2': 'ng', 'suffix_3': 'ing', 'suffix_4': 'cing', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'noticing', 'next_word': 'another', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'o', 'prefix_2': 'on', 'prefix_3': 'one', 'prefix_4': 'one', 'suffix_1': 'e', 'suffix_2': 'ne', 'suffix_3': 'one', 'suffix_4': 'one', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'one', 'next_word': 'only', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'a', 'prefix_2': 'an', 'prefix_3': 'ano', 'prefix_4': 'anot', 'suffix_1': 'r', 'suffix_2': 'er', 'suffix_3': 'her', 'suffix_4': 'ther', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'another', 'next_word': 'when', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'o', 'prefix_2': 'on', 'prefix_3': 'onl', 'prefix_4': 'only', 'suffix_1': 'y', 'suffix_2': 'ly', 'suffix_3': 'nly', 'suffix_4': 'only', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'only', 'next_word': 'they', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'w', 'prefix_2': 'wh', 'prefix_3': 'whe', 'prefix_4': 'when', 'suffix_1': 'n', 'suffix_2': 'en', 'suffix_3': 'hen', 'suffix_4': 'when', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'when', 'next_word': 'jostle', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 't', 'prefix_2': 'th', 'prefix_3': 'the', 'prefix_4': 'they', 'suffix_1': 'y', 'suffix_2': 'ey', 'suffix_3': 'hey', 'suffix_4': 'they', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'they', 'next_word': 'for', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'j', 'prefix_2': 'jo', 'prefix_3': 'jos', 'prefix_4': 'jost', 'suffix_1': 'e', 'suffix_2': 'le', 'suffix_3': 'tle', 'suffix_4': 'stle', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'jostle', 'next_word': 'cabs', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'f', 'prefix_2': 'fo', 'prefix_3': 'for', 'prefix_4': 'for', 'suffix_1': 'r', 'suffix_2': 'or', 'suffix_3': 'for', 'suffix_4': 'for', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 0, 'prev_word': 'for', 'next_word': '*T*-1', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': 'c', 'prefix_2': 'ca', 'prefix_3': 'cab', 'prefix_4': 'cabs', 'suffix_1': 's', 'suffix_2': 'bs', 'suffix_3': 'abs', 'suffix_4': 'cabs', 'word_has_hyphen': 0}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is_complete_capital': 1, 'prev_word': 'cabs', 'next_word': '.', 'is_numeric': 0, 'is_alphanumeric': 1, 'prefix_1': '*', 'prefix_2': '*T', 'prefix_3': '*T*', 'prefix_4': '*T*-', 'suffix_1': '1', 'suffix_2': '-1', 'suffix_3': '*-1', 'suffix_4': 'T*-1', 'word_has_hyphen': 1}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 1, 'is_complete_capital': 1, 'prev_word': '*T*-1', 'next_word': '', 'is_numeric': 0, 'is_alphanumeric': 0, 'prefix_1': '.', 'prefix_2': '.', 'prefix_3': '.', 'prefix_4': '.', 'suffix_1': '.', 'suffix_2': '.', 'suffix_3': '.', 'suffix_4': '.', 'word_has_hyphen': 0}]\n",
      "y training data:  ['ADP', 'NOUN', 'NOUN', 'NOUN', 'CONJ', 'NOUN', 'VERB', 'ADP', 'ADJ', 'NOUN', '.', 'X', 'VERB', 'NUM', 'DET', 'ADV', 'ADV', 'PRON', 'VERB', 'ADP', 'NOUN', 'X', '.']\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = prepare_data(train_set)\n",
    "X_test, y_test = prepare_data(test_set)\n",
    "print('X training data: ', X_train[0])\n",
    "print('y training data: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\REEHA\\anaconda3\\envs\\ibm\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.01, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a CRF model with default parameters\n",
    "crf = CRF(algorithm='lbfgs', c1=0.01, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on train data:  0.9963656348416452\n",
      "F1 score on test data:  0.9740179687208006\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = crf.predict(X_train)\n",
    "print('F1 score on train data: ', metrics.flat_f1_score(y_train, y_pred_train, average='weighted', labels=crf.classes_))\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "print('F1 score on test data: ', metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=crf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on y_train and y_pred_train:  0.9963688461823481\n",
      "Score on y_test and y_pred:  0.974124809741248\n"
     ]
    }
   ],
   "source": [
    "# Important features used to identify different POS tags\n",
    "print('Score on y_train and y_pred_train: ', metrics.flat_accuracy_score(y_train, y_pred_train))\n",
    "print('Score on y_test and y_pred: ', metrics.flat_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\REEHA\\anaconda3\\envs\\ibm\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=['ADP', 'NOUN', 'CONJ', 'VERB', 'ADJ', '.', 'X', 'NUM', 'DET', 'ADV', 'PRON', 'PRT'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classwise scores:                precision    recall  f1-score   support\n",
      "\n",
      "         ADP      0.979     0.985     0.982      1869\n",
      "        NOUN      0.966     0.977     0.972      5606\n",
      "        CONJ      0.994     0.994     0.994       480\n",
      "        VERB      0.964     0.961     0.962      2722\n",
      "         ADJ      0.909     0.877     0.893      1274\n",
      "           .      1.000     1.000     1.000      2354\n",
      "           X      1.000     0.996     0.998      1278\n",
      "         NUM      0.993     0.993     0.993       671\n",
      "         DET      0.994     0.995     0.994      1695\n",
      "         ADV      0.929     0.911     0.920       585\n",
      "        PRON      0.998     0.998     0.998       562\n",
      "         PRT      0.984     0.982     0.983       614\n",
      "\n",
      "    accuracy                          0.974     19710\n",
      "   macro avg      0.976     0.972     0.974     19710\n",
      "weighted avg      0.974     0.974     0.974     19710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Class-wise scores\n",
    "print('Classwise scores: ', metrics.flat_classification_report(y_test, y_pred, labels=crf.classes_, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transition features:  144\n",
      "\n",
      "Top 10 transition features:  [(('VERB', 'PRT'), 2.852403), (('ADJ', 'NOUN'), 2.733202), (('X', 'VERB'), 2.222562), (('PRON', 'VERB'), 1.890524), (('NOUN', 'PRT'), 1.82336), (('DET', 'X'), 1.612082), (('NUM', 'NUM'), 1.565432), (('NUM', 'NOUN'), 1.56025), (('ADP', 'PRON'), 1.494321), (('ADP', 'NOUN'), 1.475512)]\n",
      "\n",
      "Bottom 10 transition features:  [(('NOUN', 'ADJ'), -1.356654), (('PRON', 'PRT'), -1.368557), (('X', 'NOUN'), -1.536805), (('ADV', 'NOUN'), -1.540835), (('ADJ', 'PRON'), -1.543827), (('CONJ', 'X'), -1.620481), (('DET', 'ADP'), -1.791202), (('ADP', 'X'), -2.604306), (('.', 'PRT'), -2.704322), (('DET', 'PRT'), -3.860879)]\n"
     ]
    }
   ],
   "source": [
    "# Most likely transition feature\n",
    "print('Number of transition features: ', len(crf.transition_features_))\n",
    "print()\n",
    "print('Top 10 transition features: ', Counter(crf.transition_features_).most_common(10))\n",
    "print()\n",
    "print('Bottom 10 transition features: ', Counter(crf.transition_features_).most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of state features:  32285\n",
      "\n",
      "Top 10 state features:  [(('prev_word:will', 'VERB'), 6.758106), (('prefix_1:*', 'X'), 6.250123), (('prev_word:would', 'VERB'), 5.910319), (('suffix_4:rest', 'NOUN'), 5.619756), (('suffix_2:ly', 'ADV'), 5.339965), (('prev_word:could', 'VERB'), 4.994689), (('suffix_3:ous', 'ADJ'), 4.864249), (('prev_word:to', 'VERB'), 4.536444), (('prev_word:how', 'PRT'), 4.420125), (('suffix_4:will', 'VERB'), 4.402834)]\n",
      "\n",
      "Bottom 10 state features:  [(('prev_word:their', 'VERB'), -2.751858), (('prev_word:was', 'NOUN'), -2.754931), (('next_word:currency', 'NOUN'), -2.788666), (('suffix_4:good', 'NOUN'), -2.902023), (('next_word:of', 'PRT'), -3.215567), (('suffix_4:rter', 'ADJ'), -3.28299), (('prev_word:*U*', 'VERB'), -3.312148), (('next_word:swap', 'ADJ'), -3.391222), (('prev_word:his', 'VERB'), -3.648272), (('word_has_hyphen', 'VERB'), -4.765276)]\n"
     ]
    }
   ],
   "source": [
    "# Most likely state features\n",
    "print('Number of state features: ', len(crf.state_features_))\n",
    "print()\n",
    "print('Top 10 state features: ', Counter(crf.state_features_).most_common(10))\n",
    "print()\n",
    "print('Bottom 10 state features: ', Counter(crf.state_features_).most_common()[-10:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 [ibm]",
   "language": "python",
   "name": "ibm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
