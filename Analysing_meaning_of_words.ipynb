{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical 7\n",
    "\n",
    "### Read text from files, perform preprocessing activities like word sense disambiguation, tokenization and stopword removal. Create question answer context where program can read queries and respond with the correct meaning of the input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af67da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import codecs # defines a set of base classes which define the interface\n",
    "from nltk.tokenize import PunktSentenceTokenizer # abstract class for the default sentence tokenizer, i.e. sent_tokenize()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67be0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Stop words in nltk:\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bccbbd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stop words, word stemming, and get a list of word tokens\n",
    "def filtered_sent(sentence):\n",
    "    filtered_sent_list = []\n",
    "    lemmatizer = WordNetLemmatizer() # lemmatizes the words\n",
    "    stemmer = PorterStemmer() # Stemmer stems the root of the word\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(sentence)\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sent_list.append(lemmatizer.lemmatize(stemmer.stem(word)))\n",
    "        for i in synonyms_creator(word):\n",
    "            filtered_sent_list.append(i)\n",
    "    return filtered_sent_list\n",
    "            \n",
    "# Add synonyms to the match list\n",
    "def synonyms_creator(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for i in syn.lemmas():\n",
    "            synonyms.append(i.name())\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90aed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_check(word1, word2):\n",
    "    word1 += '.n.01' # word.pos.nn\n",
    "    word2 += '.n.01'\n",
    "    try:\n",
    "        w1 = wordnet.synset(word1)\n",
    "        w2 = wordnet.synset(word2)\n",
    "        return w1.wup_similarity(w2) # Returns a score denoting how similar two word senses are, based on the depth of the \n",
    "                                     # two senses in the taxonomy and that of their Least Common Subsumer (most specific \n",
    "                                     # ancestor node)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c53c0e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(similarity_check('similaritp', 'similarity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e666303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_filter(sentence):\n",
    "    filtered_sent = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(sentence)\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(word))\n",
    "    return filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6176fbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter query bats fly\n",
      "Mammal Bat\n",
      "Enter query I play with bat\n",
      "Cricket Bat\n",
      "Enter query bat is an animal\n",
      "Cricket Bat\n",
      "Enter query i hit a sixer with a bat\n",
      "Cricket Bat\n",
      "Enter query bats have eyes\n",
      "Mammal Bat\n",
      "Enter query end\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cricfile = codecs.open('cricketbat.txt', 'r', 'utf-8')\n",
    "    sent2 = cricfile.read().lower()\n",
    "    vampirefile = codecs.open('vampirebat.txt', 'r', 'utf-8')\n",
    "    sent1 = vampirefile.read().lower()\n",
    "    sent3 = input('Enter query ').lower()\n",
    "    \n",
    "    while(sent3 != 'end'):\n",
    "        \n",
    "        filtered_sent1 = []\n",
    "        filtered_sent2 = []\n",
    "        filtered_sent3 = []\n",
    "\n",
    "        counter1 = 0\n",
    "        counter2 = 0\n",
    "        sent31_similarity = 0\n",
    "        sent32_similarity = 0\n",
    "\n",
    "        filtered_sent1 = simple_filter(sent1)\n",
    "        filtered_sent2 = simple_filter(sent2)\n",
    "        filtered_sent3 = simple_filter(sent3)\n",
    "\n",
    "        for i in filtered_sent3:\n",
    "            for j in filtered_sent1:\n",
    "                counter1 = counter1 + 1\n",
    "                sent31_similarity = sent31_similarity + similarity_check(i, j)\n",
    "\n",
    "            for j in filtered_sent2:\n",
    "                counter2 = counter2 + 1\n",
    "                sent32_similarity = sent32_similarity + similarity_check(i, j)\n",
    "\n",
    "        filtered_sent1 = []\n",
    "        filtered_sent2 = []\n",
    "        filtered_sent3 = []\n",
    "\n",
    "        filtered_sent1 = filtered_sent(sent1)\n",
    "        filtered_sent2 = filtered_sent(sent2)\n",
    "        filtered_sent3 = filtered_sent(sent3)\n",
    "\n",
    "        sent1_count = 0\n",
    "        sent2_count = 0\n",
    "\n",
    "        for i in filtered_sent3:\n",
    "            for j in filtered_sent1:\n",
    "                if(i == j):\n",
    "                    sent1_count = sent1_count + 1\n",
    "            for j in filtered_sent2:\n",
    "                if(i == j):\n",
    "                    sent2_count = sent2_count + 1\n",
    "                    \n",
    "        if (sent1_count+sent31_similarity) > (sent2_count+sent32_similarity):\n",
    "            print('Mammal Bat')\n",
    "        else:\n",
    "            print('Cricket Bat')\n",
    "        \n",
    "        sent3 = input('Enter query ').lower()\n",
    "        \n",
    "print ('Terminated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
